---
title: Measuring fly eye size using R
author: "Ming Yang"
output:
  html_document:
    toc: true
    toc_depth: 2
    df_print: paged
    theme: united
date: 'Compiled: `r format(Sys.Date(), "%B %d, %Y")`'
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,message = F,warning = F) #cache = TRUE)
# blogdown::stop_server()
```

I've gained some image processing experience while doing a project using fly to study human Alzheimer's disease.

In that project, we contructed transgenic flies and used the 'GAL4/UAS system' to express human pathogenic proteins, Abeta and Tau, in fly eyes. We found, the fly eye degeneration manifested at different levels depending partly on the fly genetic background.

We hypothesized that different genetic backgrounds play a role in 'disease manifestation' and further performed GWAS to identify candidate modifier genes, which could serve as a potential target genes for tranlational medicine to aid human Alzheimer research.

(Project Github link: https://github.com/mingwhy/AD_fly_eye/tree/main/00_fly.eye.pat)

While in that project, I've implemented a different approch to analyze those degenerative fly eye images, several things actully came along.

One interesting analysis is how to measurure fly eye size/area in a automatic way.

In this post, I'd showed my code fulfilling this goal.

Let the party begin~

```{r}
library(lattice);library(ggplot2);
library(sp) #for points.in.polygon
library(raster) #for pointDistance
library(tiff);library(EBImage);library(Gmedian);
library(ggplot2);library(gridExtra)

# source supporting functions and input, output folder path
source("local-image-segmentation-func.R")
path.in="./6figs-for-test/";
path.out="./6figs-for-test-out/";
cat("input folder: ",path.in,", output folder",path.out);

# collect images
images <- list.files(path=path.in,pattern="*jpg$", full.name=F)
print(images);
n.images=length(images);

# read in images
tiffFiles=paste(path.in,images,sep='/');
tiffList <- lapply(tiffFiles, readImage)

# Resize to fit memory
tiffRes <- lapply(tiffList, resFunc)
rm(tiffList); invisible(gc()) # free memory space

# quick check for image objects dimensions
lapply(tiffRes, function(x){ dim(x)} )

# Assign resized images RGB channels to data frames
tiffOri <- lapply(tiffRes, RGBintoDF)

# White TopHat morphological transform
tiffTop <- lapply(tiffRes, function(x) wTopHat(x,y=5,z='diamond'))
# select different channels
tiffGreen<- lapply(tiffRes, function(x) channel(x, "green"))
tiffRed<- lapply(tiffRes, function(x) channel(x, "red"))

# display example images and select the proper transformation or channel
par(mfcol=c(2,3))
invisible(lapply(tiffRes[1:n.images], dispImg)) #original images
invisible(lapply(tiffTop[1:n.images], function(x) dispImgT(x, 0.99)))
invisible(lapply(tiffRes[1:n.images], function(x) dispImgT(x, 0.2)))
invisible(lapply(tiffRes[1:n.images], function(x) dispImgT(x, 0.15)))

invisible(lapply(tiffRed[1:n.images], function(x) dispImgT(x, 0.2)))
invisible(lapply(tiffRed[1:n.images], function(x) dispImgT(x, 0.15)))

par(mfcol=c(2,3))
invisible(lapply(tiffGreen[1:n.images], function(x) dispImgT(x, 0.2)))
invisible(lapply(tiffGreen[1:n.images], function(x) dispImgT(x, 0.15)))
invisible(lapply(tiffGreen[1:n.images], function(x) dispImgT(x, 0.10)))

################################################################################
# choose green channel as it captures the most intact eye shape
# test code on one image
pic=tiffGreen[[1]]

# apply differnet cutoffs to select pixels
x=quantile(pic,0.10)
x2=quantile(pic,0.50)
pic1=pic>x
pic2=pic>x2; #default black. then value add whitex
sum(pic1); 
sum(pic2)
z = abind(pic,pic1,pic2, along=1) # combine images horizontally, along=1 by row, 2 by col
display(z,title="before vs after quantile=0.1",method="raster")

# choose pic1, then `equalize`` the image
y = equalize(pic1) #hist(y);grid()
display(y, title='Equalized Grayscale Image',method="raster")
grayimage<-channel(y,"grey")
display(grayimage)

# choose thresh
nmask1 = thresh(grayimage, w=1, h=1, offset=0.05); 
nmask2 = thresh(grayimage, w=5, h=5, offset=0.05); 
nmask3 = thresh(grayimage, w=10, h=10, offset=0.5); 
z = abind(nmask1,nmask2,nmask3, along=1)
display(z,title="nmask 1-3")
nmask=nmask2; 

# choose brush
nmask1 = opening(nmask, makeBrush(3, shape='box')); 
nmask2 = opening(nmask, makeBrush(3, shape='disc')); 
nmask3 = opening(nmask, makeBrush(3, shape='diamond')); 
nmask4 = opening(nmask, makeBrush(3, shape='Gaussian')); 
nmask5 = opening(nmask, makeBrush(3, shape='line')); 
z = abind(nmask1,nmask2,nmask3,nmask4,nmask5, along=1)
display(z)
nmask=nmask3;

nmask = fillHull(nmask); 
display(nmask,title="after filling")

nmask.ori=nmask;
nmask = bwlabel(nmask); 
display(nmask); #label each pixel.cluster

cat("Number of detected pixel.cluster=",max(nmask),"\n");
max(imageData(nmask));

fts = computeFeatures.moment(nmask)
dim(fts); #m.cx     m.cy m.majoraxis m.eccentricity    m.theta

par(mfrow=c(1,2));
display(abind(pic,nmask, along=1),title="before vs after",method='raster');
display(nmask,method='raster');
text(fts[,"m.cx"], fts[,"m.cy"], 
     labels=seq_len(nrow(fts)), col="red", cex=0.8)

fts2 <- computeFeatures.shape(nmask) #s.area s.perimeter s.radius.mean s.radius.sd s.radius.min s.radius.max

#fts2[1:3,]
label=seq(1,nrow(fts2));
fts2=cbind(label,fts2);
size=c(images[1],fts2[which.max(fts2[,2]),]);
size
```

Based on the above tested image, you could choose your parameters values and then batch processing multiple images.

```{r}
# based on the selected parameters, process all images
size.all=as.numeric(); #store image size result
for(i in 1:n.images){
  pic=tiffGreen[[i]]
  x=quantile(pic,0.10)
  #x2=quantile(pic,0.50)
  pic1=pic>x
  #pic2=pic>x2; #default black. then value add whitex
  #sum(pic1); 
  #sum(pic2)
  
  ## combine images horizontally, along=1 by row, 2 by col
  #z = abind(pic,pic1,pic2, along=1) 
  #display(z,title="before vs after quantile=0.1",method="raster")
  
  y = equalize(pic1)
  #hist(y)
  #grid()
  #display(y, title='Equalized Grayscale Image',method="raster")
  
  grayimage<-channel(y,"grey")
  ##display(grayimage)
  
  #nmask1 = thresh(grayimage, w=1, h=1, offset=0.05); 
  nmask2 = thresh(grayimage, w=5, h=5, offset=0.05); 
  #nmask3 = thresh(grayimage, w=10, h=10, offset=0.5); 
  #z = abind(nmask1,nmask2,nmask3, along=1)
  #display(z,title="nmask 1-3,pick2")
  
  nmask=nmask2;
  
  #nmask1 = opening(nmask, makeBrush(3, shape='box')); 
  #nmask2 = opening(nmask, makeBrush(3, shape='disc')); 
  nmask3 = opening(nmask, makeBrush(3, shape='diamond')); 
  #nmask4 = opening(nmask, makeBrush(3, shape='Gaussian')); 
  #nmask5 = opening(nmask, makeBrush(3, shape='line')); 
  #z = abind(nmask1,nmask2,nmask3,nmask4,nmask5, along=1)
  #display(z)

  nmask=nmask3;
  
  nmask = fillHull(nmask); 
  #display(nmask,title="after filling")
  
  nmask.ori=nmask;
  nmask = bwlabel(nmask); 
  #display(nmask); #label each pixel cluster
  
  #cat("Number of omma=",max(nmask),"\n");
  max(imageData(nmask));
  
  fts = computeFeatures.moment(nmask)
  dim(fts); #m.cx     m.cy m.majoraxis m.eccentricity    m.theta
  
  par(mfrow=c(1,2));
  display(abind(pic,nmask, along=1),title="before vs after",method='raster');
  display(nmask,method='raster');
  text(fts[,"m.cx"], fts[,"m.cy"], 
       labels=seq_len(nrow(fts)), col="red", cex=0.8)
  
  fts2 <- computeFeatures.shape(nmask) #s.area s.perimeter s.radius.mean s.radius.sd s.radius.min s.radius.max
  
  #fts2[1:3,]
  label=seq(1,nrow(fts2));
  fts2=cbind(label,fts2);
  size=c(images[i],fts2[which.max(fts2[,2]),]);
  size.all=rbind(size.all,size);
}

size.all

```

As you can see, most images' eye area were detected pretty nicely, but there are some 'outliers'.

As all intermediate plots were generated, you could easily select those 'outlier' images and refine your paramter to get a more accurate measurement.

Have fun~

```{r}
installed.packages()[names(sessionInfo()$otherPkgs), "Version"]
#devtools::session_info()
```
